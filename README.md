# BASE DE DATOS 2 
## Proyecto 2

## Integrantes 锔

- Juan Pablo Lozada [IWeseI] Participaci贸n: 100%
- Alexandra Shulca [Alexandra-SR] Participaci贸n: 100%
- Alex Loja Zumaeta [aljozu] Participaci贸n: 100%

## Profesor 

- Heider Sanchez Enriquez

## Asistente de docencia
- Juan Galvez Ccopa


## Introducci贸n :dart:

**_Objetivo:_**  Entender y aplicar los algoritmos de b煤squeda y recuperaci贸n de informaci贸n basado en el contenido. En este proyecto nos enfocaremos en la construcci贸n 贸ptima de un _ndice Invertido_. En este caso usaremos un dataset de tweets, que nos permitir谩 encontrar los tweets m谩s relevantes dado un t茅rmino de b煤squeda. 

**_Descripci贸n del dominio:_** Usaremos una base de datos que cuenta con la informaci贸n de [carros usados de la marca Audi](https://www.kaggle.com/mysarahmadbhat/audi-used-car-listings). Existen m谩s de 10 mil registros y por cada uno tenemos la siguiente informaci贸n:

- **Id**: N煤mero de identificaci贸n.
- **Model**: Modelo de Audi.


**_Resultados esperados:_** Se espera poder hacer inserci贸n de registros, b煤squeda por rango, b煤squeda espec铆fica y eliminaci贸n de acuerdo al id.


## Comenzando 

### Pre-requisitos 
* [C++ 17](https://nuwen.net/mingw.html) 

### Despliegue 

**1.** Clonar el repositorio del proyecto.

**2.** Realizar el Build del proyecto en su IDE de preferencia.

**3.** Ejecutar el programa


## Descripci贸n de las t茅cnicas 

- **Preprocesamiento:** 
  o Tokenization 
  o Filtrar Stopwords 
  o Reducci贸n de palabras (Stemming) 
- **Construcci贸n del ndice**
  o Estructurar el 铆ndice invertido para guardar los pesos TF-IDF.  
  o Calcular  una  sola  vez  la  longitud  de  cada  documento  (norma)  y  guardarlo  para  ser 
  utilizado al momento de aplicar la similitud de coseno. 
  o Construcci贸n del 铆ndice en memoria secundaria para grandes colecciones de datos.   
- **Consulta** 
  o La consulta es una frase en lenguaje natural.  
  o El scoring se obtiene aplicando la similitud de coseno sobre el 铆ndice invertido en 
  memoria secundaria. 
  o La funci贸n de recuperac
  i贸n debe retornar una lista ordenada de documentos que se 
  aproximen a la consulta. 

###  SEQUENTIAL FILE  

**_Sequential file_**: En este m茅todo organizamos los registros de acuerdo a un valor de sus campos, para este caso usaremos el campo **Id** como key.

- **B煤squeda:**

  1.  Abrir el archivo de datos.
  2.  Iniciar b煤squeda binaria.
  3.  Ubicar el puntero a la mitad del archivo de datos.
  4.  Comparar el id del regsitro encontrado con el id del registro entrante.
  5.  Mover el puntero de acuerdo al tama帽o del id hasta encontrar una coincidencia.
  6.  Se lee el registro y tenemos 3 posibilidades:  
      6.1 El registro encontrado esta en el archivo principal entonces devolvemos el registro.  
      6.2 El registro encontrado ha sido eliminado, en este caso recorremos el archivo hasta encontrar el primer registro no borrado.  
      6.3 El registro se encuentra en el archivo auxiliar.
      - Se abre el archivo auxiliar.
      - Se recorre el archivo hasta encontrar una coincidencia.
      - Si se encuentra se devuelve el registro.
      - Si no se encuentra se devuelve el registro m谩s cercano anterior al id del regsitro buscado.
      - Se cierra el archivo auxiliar.
  7.  Se cierra el archivo principal de datos.


#### B煤squeda espec铆fica
````c++

 

````


- **Inserci贸n:**

  1. Abrimos el archivo auxiliar.
  2. Comprobamos si hay espacio.  
     2.1 Si no hay espacio se leen todos los registros y se insertan al archivo principal.  
     2.2 Si hay espacio se busca el registro anterior en el archivo principal.  
     2.3 Se actualizan los punteros.  
     2.4 Se escribe el registro.
  3. Se cierra el archivo.

#### Inserci贸n
````c++
 
````

- **Eliminaci贸n:**

  1. Se busca el registro que va antes del registro actual.
  2. Se actualizan los punteros del registro anterior.
  3. Se marca el registro como eliminado.
  4. Se hace update a los registros modificados.

#### Eliminaci贸n
````c++



````
- **B煤squeda por rango:**

  1. Se busca el archivo registro inicial.
  2. Se itera a帽adiendo los registros hasta llegar al registro final.
  3. Retorna un vector de registros.



#### B煤squeda por rango 
````c++


  
````


* **Ventajas:**
  - Al ser un arhivo ordenado la b煤squeda de registros se realizar谩 siempre en log(n).


---

###  Extendible Hashing 

**_Extendible Hashing:_** El hash extensible es una estructura que se actualiza din谩micamente y que implementa un esquema de hash utilizando un directorio. El 铆ndice se utiliza para encontrar consultas donde exista un registro con una key determinada.

- **B煤squeda:**

  1. Calculamos el hash de la key que queremos buscar.
  2. Verificamos la cantidad de bits(**n**) que se usan en el directorio.
  3. Tomar los n bits de la direcci贸n hash.
  4. Usando este 铆ndice encontrar el bucket al que pertenece el registro.
  5. Leer todos los registros en ese bucket.
  6. Recorrer los registro le铆dos.
  7. Retornar el registro encontrado.
  8. Cerrar el archivo.

#### B煤squeda espec铆fica
````c++
 vector<Car> search(int key) {
    Car record;
    int totalRecords, deleteNext;
    vector<Car> result;
    fstream file; 

    string bucketName= getBucket(key); 
    string bucket = bucketName +".dat";
    
    file.open(bucket, ios::binary | ios::out | ios::in );
    file.read((char *) &totalRecords, sizeof(int));
    file.read((char *) &deleteNext, sizeof(int));
    for (unsigned int i = 0; i < totalRecords; i++) {
      file.read((char *) &record, sizeof(record));
    // -1 means that the record  is not deleted
      if (record.id == key && record.deleteNext == -2)
        {result.push_back(record);}
    }
    if (result.empty()){
      cerr<<"Key not found in search "<<endl;
    }
    file.close();
    return result;
  }
````

- **Inserci贸n:**

  1. Calculamos el hash de la key que queremos buscar.
  2. Verificamos la cantidad de bits(**n**) que se usan en el directorio.
  3. Tomar los n bits de la direcci贸n hash.
  4. Usando este 铆ndice encontrar el bucket al que pertenece el registro.
  5. Comprobamos que la key no se encuentre en el Bucket.
  6. Tenemos dos casos:
     - El bucket a煤n no esta completo.
       - Insertamos el registro.
     - El bucket est谩 completo.
       - Creamos el nuevo bucket.
       - Reinsertamos todos los registros.
       - Se crean los nuevos buckets con la nueva profundidad local.
       - Se actualiza el directorio.

#### Inserci贸n 
````c++


````

- **Eliminaci贸n:**

  1. Calculamos el hash de la key que queremos buscar.
  2. Verificamos la cantidad de bits(**n**) que se usan en el directorio.
  3. Tomar los n bits de la direcci贸n hash.
  4. Usando este 铆ndice encontrar el bucket al que pertenece el registro.
  5. Leer los datos del registro.
  6. Eliminar el registro.
  7. Si el bucket queda vacio, liberar la memoria.
  8. Actualizar el directorio.
  9. Leer el directorio.
     - Si existen dos buckets con pocos elementos y el mismo prefijo en la profundidad anterior se puden mezclar.
     - Crear un nuevo bucket.
     - Leer los registros de los dos buckets.
     - Liberar los dos buckets pasados.
     - Escribir los registros en el nuevo bucket.
     - Actualizamos el directorio.
     - Cerrar el directorio.

#### Eliminaci贸n 
````c++



````

* **Ventajas:**
  - Es eficaz mientras la memoria principal soporte el directorio.
  - La eficiencia se mantiene con el crecimiento del archivo de datos.
  - La cantidad de reescrituras no es tan grande.  

## Resultados Experimentales  
  
  ***Sequential File***  
  
  ![Tiempo vs Operaci贸n por registro](/Imagenes/SF_ExecutionTimes.png)  
  - Podemos observar como los tiempos de inserci贸n aumentan cada cierta cantidad de operaciones, ya que al acabarse el espacio auxiliar los registros son escritos en memoria secundaria y ordenados de acuerdo a su key.
  - Los tiempos de b煤squeda y eliminaci贸n solo aumentan cuando el registro se encuentra en el archivo auxiliar, caso contrario su tiempo de ejecuci贸n se mantiene constante.

  ***Extendible Hashing***
  
  ![Tiempo vs Operaci贸n por registro](/Imagenes/EH_ExecutionTimes.png)
  - Los tiempos de b煤squeda son constantes en cualquier moment.
  - Los picos de tiempo en insertar se dan porque en alg煤n momento se necesita hacer split de algun bucket.
  - Los tiempos altos en eliminar se dan porque se necesita hacer merge entre dos buckets con cantidad baja de registros. 


## Evidencias 

* [Video](https://drive.google.com/drive/folders/1FY2bS6usvtPjwruH39Gzagi8iZs4J8BQ?usp=sharing) 

  
